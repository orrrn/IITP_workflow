{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35a80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801223d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.font_manager\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18140812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ask user for the dataset1 path\n",
    "path1 = input(\"Enter the path to the dataset-1: \")\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    data = pd.read_csv(path1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the dataset: {e}: please restart the program\")\n",
    "    exit()\n",
    "    #C:\\Users\\JILCHALELISAADEBA\\test_set-2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the index column\n",
    "data.drop(columns=data.columns[0], axis=1,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "def normalization(dat,column):\n",
    "  for i in column:\n",
    "    arr = dat[i]\n",
    "    arr = np.array(arr)\n",
    "    dat[i] = scaler.fit_transform(arr.reshape(len(arr),1))\n",
    "  return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fae514",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = normalization(data.copy(),data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the test DataFrame\n",
    "test_df = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te = test_df['label']\n",
    "test_df.drop('label', axis=1, inplace=True)\n",
    "test_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dataset to numpy array, before converting to torch tensor\n",
    "x_te_np = test_df.to_numpy().astype(np. float32) \n",
    "y_te_np = y_te.to_numpy().astype(np. float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b58c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors\n",
    "X_te_tensor = torch.tensor(x_te_np)\n",
    "y_te_tensor = torch.tensor(y_te_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064addb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632cbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and testing\n",
    "batch_size = 32\n",
    "test_dataset = CustomDataset(X_te_tensor, y_te_tensor.reshape(-1, 1))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc176ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class abstruction of LSTM_VAE model\n",
    "class LSTM_AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc1 = nn.LSTM(\n",
    "          input_size=240,\n",
    "          hidden_size=128,\n",
    "          num_layers=1,\n",
    "          batch_first=True,\n",
    "          dropout = 0.6\n",
    "        )\n",
    "        self.enc2 = nn.LSTM(\n",
    "          input_size=128,\n",
    "          hidden_size=4,\n",
    "          num_layers=1,\n",
    "          batch_first=True,\n",
    "          dropout = 0.6\n",
    "        )\n",
    "        \n",
    "        self.dec1 = nn.LSTM(\n",
    "          input_size=4,\n",
    "          hidden_size=128,\n",
    "          num_layers=1,\n",
    "          batch_first=True,\n",
    "          dropout = 0.6\n",
    "        )\n",
    "        self.dec2 = nn.LSTM(\n",
    "          input_size=128,\n",
    "          hidden_size=240,\n",
    "          num_layers=1,\n",
    "          batch_first=True,\n",
    "          dropout = 0.6\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (_, _) = self.enc1(x)\n",
    "        x, (hidden_n, _) = self.enc2(x)\n",
    "        x, (hidden_n, cell_n) = self.dec1(x)\n",
    "        x, (hidden_n, cell_n) = self.dec2(x)\n",
    "        return  x\n",
    "    \n",
    "    def run_encoder(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        latent  = x\n",
    "        return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class abstraction of FC classifier \n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        #self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size3, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        #x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class abstraction of Conv_VAE model\n",
    "class Conv_VAE(nn.Module):\n",
    "    def __init__(self, kernel_size = 2,\n",
    "                init_channels = 8, \n",
    "                data_channels = 1, \n",
    "                latent_dim = 32): \n",
    "        super(ConvVAE6, self).__init__()\n",
    " \n",
    "        # encoder (in_channels=1, out_channels=1, kernel_size=3, stride=1)\n",
    "        self.enc1 = nn.Conv1d(\n",
    "            in_channels=1, out_channels=init_channels, kernel_size=kernel_size,stride=1, padding=0)\n",
    "        self.enc2 = nn.Conv1d(\n",
    "            in_channels=init_channels, out_channels=init_channels*2, kernel_size=kernel_size,stride=1, padding=1)\n",
    "        self.enc3 = nn.Conv1d(\n",
    "            in_channels=init_channels*2, out_channels=init_channels*4, kernel_size=kernel_size,stride=2, padding=1)\n",
    "        self.enc4 = nn.Conv1d(\n",
    "            in_channels=init_channels*4, out_channels=64, kernel_size=kernel_size,stride=2, padding=0)\n",
    "        \n",
    "        # FC for teh hidden representations\n",
    "        self.fc1 = nn.Linear(61, 128)\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(128, latent_dim)\n",
    "        self.fc2 = nn.Linear(latent_dim, 64)\n",
    "        # decoder \n",
    "        self.dec1 = nn.ConvTranspose1d(\n",
    "            in_channels=64, out_channels=init_channels*8, kernel_size=kernel_size,stride=1, padding=0)\n",
    "        self.dec2 = nn.ConvTranspose1d(\n",
    "            in_channels=init_channels*8, out_channels=init_channels*4, kernel_size=kernel_size,stride=2, padding=2)\n",
    "        self.dec3 = nn.ConvTranspose1d(\n",
    "            in_channels=init_channels*4, out_channels=init_channels*2, kernel_size=kernel_size,stride=2, padding=3)\n",
    "        self.dec4 = nn.ConvTranspose1d(\n",
    "            in_channels=init_channels*2, out_channels=data_channels, kernel_size=kernel_size,stride=1, padding=2)\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        #standard deviation\n",
    "        std = torch.exp(0.5*log_var) \n",
    "        #`randn_like` as we need the same size\n",
    "        eps = torch.randn_like(std) \n",
    "        #sampling\n",
    "        sample = mu + (eps * std) \n",
    "        return sample\n",
    " \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = torch.nn.functional.relu(self.enc1(x))\n",
    "        x = torch.nn.functional.relu(self.enc2(x))\n",
    "        x = torch.nn.functional.relu(self.enc3(x))\n",
    "        x = torch.nn.functional.relu(self.enc4(x))\n",
    "    \n",
    "        batch, _, _ = x.shape\n",
    "        #x = F.adaptive_avg_pool1d(x, 64).reshape(batch, -1)\n",
    "        #print(x.shape)\n",
    "        hidden = self.fc1(x)\n",
    "        # get `mu` and `log_var`\n",
    "        mu = self.fc_mu(hidden)\n",
    "        log_var = self.fc_log_var(hidden)\n",
    "        \n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        z = self.fc2(z)\n",
    "        z = z.view(-1, 64)\n",
    "        #print(z.shape[0])\n",
    "        z = z.view(-1, z.shape[0]//64, 64)\n",
    "        z = torch.moveaxis(z, 0, 1)\n",
    "        \n",
    "        # decoding\n",
    "        x = torch.nn.functional.relu(self.dec1(z))\n",
    "        x = torch.nn.functional.relu(self.dec2(x))\n",
    "        x = torch.nn.functional.relu(self.dec3(x))\n",
    "        reconstruction = torch.sigmoid(self.dec4(x))\n",
    "        reconstruction = reconstruction[:, :, :59]\n",
    "        return reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603710e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask user for the model path\n",
    "path3 = input(\"Enter the path to the model: \")\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    model = torch.load(path3, map_location=torch.device('cpu'))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the model: {e}: please restart the program\")\n",
    "    exit()\n",
    "    #C:\\Users\\JILCHALELISAADEBA\\ISAA-IITP_trained_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b720e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inps = inputs\n",
    "        labs = labels\n",
    "        outs = model(inps)\n",
    "        predicted = (torch.sigmoid(outs) > 0.5).float()\n",
    "        \n",
    "        y_true.extend(labs.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        total += labs.size(0)\n",
    "        correct += (predicted == labs).sum().item()\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_true, y_pred))\n",
    "print('F1 score: ', f1_score(y_true, y_pred))\n",
    "print('Recall: ', recall_score(y_true, y_pred))\n",
    "print('Precision: ', precision_score(y_true, y_pred))\n",
    "print('\\n clasification report:\\n ', classification_report(y_true, y_pred))\n",
    "print('\\n confussion matrix:\\n ',confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7eee78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
